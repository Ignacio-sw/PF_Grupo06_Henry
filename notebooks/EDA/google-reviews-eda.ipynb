{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apertura de un archivo JSON para verificar estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reviews=pd.read_json(r\"C:\\Users\\Usuario\\Desktop\\GitHub\\DataSets\\DataLake\\REVIEW-ESTADOS\\reviews-estados\\review-Alabama\\1.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.140438e+20</td>\n",
       "      <td>Kanisha Mixon</td>\n",
       "      <td>1597168272670</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Personable staff! Beautiful and clean env...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x8862134e67ff5c87:0x38b5e2ae99cd1fcf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.160090e+20</td>\n",
       "      <td>Brandie Hodges</td>\n",
       "      <td>1609899039594</td>\n",
       "      <td>5</td>\n",
       "      <td>Best clothing intown</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x8862134e67ff5c87:0x38b5e2ae99cd1fcf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id            name           time  rating  \\\n",
       "0  1.140438e+20   Kanisha Mixon  1597168272670       5   \n",
       "1  1.160090e+20  Brandie Hodges  1609899039594       5   \n",
       "\n",
       "                                                text  pics  resp  \\\n",
       "0  Very Personable staff! Beautiful and clean env...  None  None   \n",
       "1                               Best clothing intown  None  None   \n",
       "\n",
       "                                 gmap_id  \n",
       "0  0x8862134e67ff5c87:0x38b5e2ae99cd1fcf  \n",
       "1  0x8862134e67ff5c87:0x38b5e2ae99cd1fcf  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   user_id  150000 non-null  float64\n",
      " 1   name     150000 non-null  object \n",
      " 2   time     150000 non-null  int64  \n",
      " 3   rating   150000 non-null  int64  \n",
      " 4   text     82943 non-null   object \n",
      " 5   pics     3087 non-null    object \n",
      " 6   resp     20893 non-null   object \n",
      " 7   gmap_id  150000 non-null  object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL\n",
    "#eliminado de columnas PICS y RESP\n",
    "data_reviews.drop(columns=[\"pics\", \"resp\"], inplace=True)\n",
    "# Convertir la columna 'time' a formato de fecha y hora\n",
    "data_reviews['time'] = pd.to_datetime(data_reviews['time'], unit='ms')\n",
    "\n",
    "for columna in data_reviews.columns:\n",
    "    if data_reviews[columna].dtype == 'object':\n",
    "        # Si la columna es de texto, llenar los valores nulos con \"No data\" y eliminar espacios en blanco y saltos de línea\n",
    "        data_reviews[columna] = data_reviews[columna].fillna(\"No data\").str.strip()\n",
    "    elif data_reviews[columna].dtype in ['int64', 'float64']:\n",
    "        # Si la columna es numérica, llenar los valores nulos con 0\n",
    "        data_reviews[columna] = data_reviews[columna].fillna(0)\n",
    "\n",
    "# Eliminar duplicados basados en las columnas 'gmap_id' y 'user_id'\n",
    "data_reviews.drop_duplicates(subset=['gmap_id', 'user_id'], inplace=True)\n",
    "#cambiar tipo dato columna user_id a string\n",
    "data_reviews['user_id'] = data_reviews['user_id'].astype(str)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 147686 entries, 0 to 149999\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count   Dtype         \n",
      "---  ------   --------------   -----         \n",
      " 0   user_id  147686 non-null  object        \n",
      " 1   name     147686 non-null  object        \n",
      " 2   time     147686 non-null  datetime64[ns]\n",
      " 3   rating   147686 non-null  int64         \n",
      " 4   text     147686 non-null  object        \n",
      " 5   gmap_id  147686 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux=data_reviews.sample(n=50000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux.to_json(\"review.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ETL_reviews_bigquery(cloud_event):\n",
    "    try:\n",
    "        data = cloud_event.data\n",
    "        event_id = cloud_event[\"id\"]\n",
    "        event_type = cloud_event[\"type\"]\n",
    "\n",
    "        bucket = data[\"bucket\"]\n",
    "        name = data[\"name\"]\n",
    "        timeCreated = data[\"timeCreated\"]\n",
    "        updated = data[\"updated\"]\n",
    "\n",
    "        # Obtén la carpeta en el bucket desde los parámetros de la URL\n",
    "        lista_carpetas=name.split(\"/\")\n",
    "        estado = lista_carpetas[2]\n",
    "        estado=estado.split(\"-\")\n",
    "        estado=estado[1]\n",
    "\n",
    "        # Crea un cliente de Cloud Storage\n",
    "        storage_client = storage.Client()\n",
    "\n",
    "        file_path = f'gs://{bucket}/{name}'\n",
    "        # Convierte la lista de objetos JSON en un DataFrame de Pandas\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "        print(\"leyo bien\")\n",
    "\n",
    "        #ETL\n",
    "        #eliminado de columnas PICS y RESP\n",
    "        df.drop(columns=[\"pics\", \"resp\"], inplace=True)\n",
    "        # Convertir la columna 'time' a formato de fecha y hora\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "\n",
    "        for columna in df.columns:\n",
    "            if df[columna].dtype == 'object':\n",
    "                # Si la columna es de texto, llenar los valores nulos con \"No data\" y eliminar espacios en blanco y saltos de línea\n",
    "                df[columna] = df[columna].fillna(\"No data\").str.strip()\n",
    "            elif df[columna].dtype in ['int64', 'float64']:\n",
    "                # Si la columna es numérica, llenar los valores nulos con 0\n",
    "                df[columna] = df[columna].fillna(0)\n",
    "        \n",
    "        # Eliminar duplicados basados en las columnas 'gmap_id' y 'user_id'\n",
    "        df.drop_duplicates(subset=['gmap_id', 'user_id'], inplace=True)\n",
    "        #cambiar tipo dato columna user_id a string\n",
    "        df['user_id'] = df['user_id'].astype(str)\n",
    "\n",
    "        #agregamos la columna state para indicar de que estado proviene cada review\n",
    "        df['state'] = estado\n",
    "\n",
    "        #iniciamos el cliente de BigQuery\n",
    "        client = bigquery.Client()\n",
    "        \n",
    "        project_id='dms-pfh'\n",
    "        dataset_id = 'google'\n",
    "        table_id = 'google-sites'\n",
    "        full_table_id = f'{project_id}.{dataset_id}.{table_id}'\n",
    "\n",
    "        #leemos los sitios que vamos a utilizar para luego cargar solo las reviews de estos sitios\n",
    "        tabla = client.get_table(full_table_id)\n",
    "\n",
    "        #guardamos la tabla en un dataframe\n",
    "        df_sitios = client.list_rows(tabla).to_dataframe()\n",
    "\n",
    "        df_filtrado = pd.merge(df, df_sitios[['gmap_id']], on='gmap_id', how='inner')\n",
    "\n",
    "        print(f\"Cantidad de filas de df_filtrado={df_filtrado.shape}\")\n",
    "\n",
    "        #CARGA EN BIG QUERY:\n",
    "        client = bigquery.Client()\n",
    "\n",
    "        # Especifica el nombre del conjunto de datos y la tabla\n",
    "\n",
    "        # Configura el job de carga con autodetección de esquema\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            autodetect=True,  # Permite a BigQuery autodetectar el esquema\n",
    "            create_disposition=\"CREATE_IF_NEEDED\",\n",
    "            write_disposition=\"WRITE_APPEND\" \n",
    "        )\n",
    "\n",
    "\n",
    "        table_id = 'reviews'\n",
    "        full_table_id = f'{project_id}.{dataset_id}.{table_id}'\n",
    "\n",
    "        # Inicia el job de carga\n",
    "        load_job = client.load_table_from_dataframe(df_filtrado, full_table_id, job_config=job_config, location=\"us-central1\")\n",
    "\n",
    "        # Espera a que el job se complete\n",
    "        load_job.result()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en la función: {e}\", exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
