{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "# Importar modulo processing\n",
    "#from processing import procesar, hash_category\n",
    "\n",
    "# Instatiate clients\n",
    "cloud_storage = storage.Client()\n",
    "bq = bigquery.Client()\n",
    "\n",
    "project_id = 'dms-pfh'\n",
    "\n",
    "\n",
    "def archivo_df_business(file_uri):\n",
    "    # Crear una instancia del cliente de Google Cloud Storage\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Nombre del archivo en el bucket\n",
    "    nombre_archivo = 'df_mascara.csv'\n",
    "\n",
    "    # Nombre del bucket\n",
    "    nombre_bucket = 'yelp_dms'\n",
    "    # Ruta completa en el bucket\n",
    "    ruta_archivo = f'gs://{nombre_bucket}/{nombre_archivo}'\n",
    "    \n",
    "    # Filtrado segun nombre archivo para su respectivo ETL\n",
    "    df_bussines = pd.read_pickle(file_uri)\n",
    "    df_bussines =df_bussines.loc[:,~df_bussines.columns.duplicated()].copy()\n",
    "    print(\"pase la mascara de juan de columnas\")\n",
    "    df_bussines.drop(columns=[\"is_open\",'attributes', 'hours','postal_code'], inplace=True)\n",
    "    categorias_deseadas = [\"restaurant\", \"bar\", \"pub\", \"cafe\", 'bakery', 'coffee shop', 'gym', 'gas station']\n",
    "\n",
    "    # Eliminar filas con valores NaN en la columna 'categories'\n",
    "    df_bussines = df_bussines.fillna(\"No Data\")\n",
    "    # Filtrar el DataFrame para mantener solo las filas que contienen al menos una de las categorías deseadas\n",
    "    df_bussines = df_bussines[df_bussines['categories'].str.contains('|'.join(categorias_deseadas), case=False)]\n",
    "    df_mascara= df_bussines[\"business_id\"]\n",
    "    \n",
    "\n",
    "    # Guardar el DataFrame como un archivo CSV\n",
    "    df_mascara.to_csv(nombre_archivo, index=False)\n",
    "    # Obtener el bucket\n",
    "    bucket = client.bucket(nombre_bucket)\n",
    "    # Subir el archivo al bucket\n",
    "    blob = bucket.blob(nombre_archivo)\n",
    "    blob.upload_from_filename(nombre_archivo)\n",
    "    print(f'DataFrame guardado en {ruta_archivo}')\n",
    "\n",
    "\n",
    "    return df_bussines\n",
    "\n",
    "def archivo_df_tip(file_uri):\n",
    "    df_tip = pd.read_json(file_uri, lines=True)\n",
    "    df_tip.drop(columns=\"compliment_count\", inplace=True)\n",
    "    for columna in df_tip.columns:\n",
    "        if df_tip[columna].dtype == 'object':\n",
    "            # Si la columna es de texto, llenar los valores nulos con \"No data\" y eliminar espacios en blanco y saltos de línea\n",
    "            df_tip[columna] = df_tip[columna].fillna(\"No data\").str.strip()\n",
    "        elif df_tip[columna].dtype in ['int64', 'float64']:\n",
    "            # Si la columna es numérica, llenar los valores nulos con 0\n",
    "            df_tip[columna] = df_tip[columna].fillna(0)\n",
    "    return df_tip\n",
    "\n",
    "def archivo_df_user(file_uri):\n",
    "    df_user001 = pd.read_json(file_uri, lines=True)\n",
    "    df_user001.drop(columns=['elite','friends','compliment_hot','compliment_more', 'compliment_profile', 'compliment_cute','compliment_list', 'compliment_note', 'compliment_plain',\n",
    "        'compliment_cool', 'compliment_funny', 'compliment_writer','compliment_photos'], inplace=True)\n",
    "    for columna in df_user001.columns:\n",
    "        if df_user001[columna].dtype == 'object':\n",
    "            # Si la columna es de texto, llenar los valores nulos con \"No data\" y eliminar espacios en blanco y saltos de línea\n",
    "            df_user001[columna] = df_user001[columna].fillna(\"No data\").str.strip()\n",
    "        elif df_user001[columna].dtype in ['int64', 'float64']:\n",
    "            # Si la columna es numérica, llenar los valores nulos con 0\n",
    "            df_user001[columna] = df_user001[columna].fillna(0)\n",
    "    print(\"completado etl archivo parquet\")\n",
    "    return df_user001\n",
    "\n",
    "def archivo_df_review(file_uri):\n",
    "    df_review = pd.read_json(file_uri, lines=True)\n",
    "    #for columna in df_review.columns:\n",
    "        #if df_review[columna].dtype == 'object':\n",
    "        # Si la columna es de texto, llenar los valores nulos con \"No data\" y eliminar espacios en blanco y saltos de línea\n",
    "        #    df_review[columna] = df_review[columna].fillna(\"No data\").str.strip()\n",
    "    #    if df_review[columna].dtype in ['int64', 'float64']:\n",
    "                    # Si la columna es numérica, llenar los valores nulos con 0\n",
    "    #        df_review[columna] = df_review[columna].fillna(0)\n",
    "    df_mascara=pd.read_csv(\"gs://yelp_dms/df_mascara.csv\")\n",
    "    print(\"carga de mascara completada\")\n",
    "    df_review['business_id'] = df_review['business_id'].astype(str)\n",
    "    df_mascara['business_id'] = df_mascara['business_id'].astype(str)\n",
    "\n",
    "    df_review = pd.merge(df_review, df_mascara, on='business_id', how='inner')\n",
    "    print(\"filtracion completa en archivo REVIEW\")\n",
    "    return df_review\n",
    "\n",
    "# Triggered by a change in a storage bucket\n",
    "@functions_framework.cloud_event\n",
    "def load_df(cloud_event):\n",
    "    data = cloud_event.data\n",
    "    event_id = cloud_event[\"id\"]\n",
    "    event_type = cloud_event[\"type\"]\n",
    "    print(f'Cloud event ID: {event_id}')\n",
    "    print(f'Event type: {event_type}')\n",
    "    bucket_name = data[\"bucket\"]\n",
    "    name = data[\"name\"]\n",
    "    print(f'Bucket: {bucket_name}')\n",
    "    print(f'File name: {name}')\n",
    "    # Create URI\n",
    "    file_uri = f'gs://{bucket_name}/{name}'\n",
    "    print(f'URI: {file_uri}')\n",
    "    # Obtener el objeto del bucket\n",
    "    bucket = cloud_storage.bucket(bucket_name)\n",
    "    # Obtener el blob (objeto) del archivo JSON en el bucket\n",
    "    blob = bucket.blob(name)\n",
    "    # Attempt to create DataFrame with URI\n",
    "    # Attempt to process DataFrame\n",
    "    print('Transformando dataframe...')\n",
    "    try:\n",
    "        if \"business\" in file_uri:\n",
    "            df_procesado = archivo_df_business(file_uri)\n",
    "            table_name = \"yelp-sites\"\n",
    "            print(\"dataframe cargado\") \n",
    "        if \"tip\" in file_uri:\n",
    "            df_procesado = archivo_df_tip(file_uri)\n",
    "            table_name = \"yelp-user-tips\"\n",
    "            print(\"dataframe cargado\")\n",
    "        if \"user\" in file_uri:\n",
    "            df_procesado = archivo_df_user(file_uri)\n",
    "            table_name = \"yelp-user-info\"\n",
    "            print(\"dataframe cargado\")\n",
    "        if \"parte_\" in file_uri:\n",
    "            df_procesado=archivo_df_review(file_uri)\n",
    "            table_name=\"yelp-user-review\"\n",
    "            print(\"dataframe cargado\")\n",
    "        print('DataFrame Procesado')\n",
    "        print('Nuevas dimensiones:', df_procesado.shape)\n",
    "    except Exception as e:\n",
    "        # Cuando no procesa la información\n",
    "        print('DataFrame no pudo ser procesado: Error - ', e)\n",
    "        return None\n",
    "    # Insert to table\n",
    "    table_id = f'dms-pfh.yelp_data.{table_name}'\n",
    "    # Create job configurations\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        autodetect=True,\n",
    "        create_disposition='CREATE_IF_NEEDED',\n",
    "        write_disposition='WRITE_APPEND'\n",
    "        # source_format='NEWLINE_DELIMITED_JSON'\n",
    "    )\n",
    "    print('Job configuration created.')\n",
    "    # Requesting the job\n",
    "    load_job = bq.load_table_from_dataframe(\n",
    "        df_procesado,\n",
    "        table_id,\n",
    "        location='us-central1',\n",
    "        job_config=job_config\n",
    "    )\n",
    "    load_job.result()\n",
    "    print('Job finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
